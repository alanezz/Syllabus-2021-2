{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789c6d0d",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "En este _notebook_ vamos a aprender sobre _autoencoders_. Un _autoencoders_ es un tipo de red neuronal que aprende a encontrar un _encoding_ eficiente para un _dataset_; por lo tanto, es un tipo de aprendizaje no supervisado, y puede utilizarse para reducir dimensionalidad de un _dataset_. \n",
    "\n",
    "En este ejemplo vamos a trabajar con el _dataset_ MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f21cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=True)\n",
    "mnist.keys()\n",
    "\n",
    "X, y = mnist['data'], mnist['target']\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ea917",
   "metadata": {},
   "source": [
    "Al igual que cuando utilizábamos PCA, es recomendable estandarizar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a509c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_sclr = StandardScaler()\n",
    "X_train_std = std_sclr.fit_transform(X_train)\n",
    "X_test_std = std_sclr.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76766ff1",
   "metadata": {},
   "source": [
    "## Reduciendo dimensiones con un autoencoder\n",
    "\n",
    "La idea general del _autoencoder_ es aprovecharnos de que una red neuronal puede aprender su propia representación de los datos. Supongamos que tenemos una red con una única _hidden layer_; a grandes rasgos, esta _layer_ lo que hace es aprender la representación más apropiada para resolver el problema. Así, un _autoencoder_ en vez de entregarnos un _output_ (por ejemplo, una respuesta de un problema de clasificación), nos entrega una representación en menos dimensiones.\n",
    "\n",
    "El _autoencoder_ se divide en dos componentes, una red neuronal **_encoder_** y otra red **_decoder_**. La red _encoder_ aprende a tomar una instancia y representarla en una nueva dimensionalidad, mientras que la red _decoder_ toma una instancia en la nueva dimensionalidad y la deja en la dimensión original.\n",
    "\n",
    "¿Pero cómo entrenamos esta red? La idea es primero instanciar la red _enconder_, luego la red _decoder_, y hacer que el _output_ de la red _encoder_ sea el _input_ de la _decoder_. Esto forma una gran red que será nuestro _autoencoder_. La parte interesante es que el input del _autoencoder_ son las instancias que queremos reducir, y para cada instancia, su respuesta es la misma instancia, ya que lo que queremos es que la respuesta del _autoencoder_ (es decir, la respuesta de la red _decoder_) sea la misma instancia que habíamos entregado al _autoencoder_ (es decir, el _input_ del _encoder_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0afef355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8342 - val_loss: 0.7635\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.7499 - val_loss: 0.7478\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 2s 939us/step - loss: 0.7451 - val_loss: 0.7456\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 2s 931us/step - loss: 0.7438 - val_loss: 0.7448\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 2s 915us/step - loss: 0.7432 - val_loss: 0.7445\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 2s 918us/step - loss: 0.7430 - val_loss: 0.7441\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 0.7429 - val_loss: 0.7441\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 2s 916us/step - loss: 0.7427 - val_loss: 0.7440\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 2s 926us/step - loss: 0.7427 - val_loss: 0.7438\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.7426 - val_loss: 0.7439\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 2s 936us/step - loss: 0.7426 - val_loss: 0.7438\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 2s 914us/step - loss: 0.7426 - val_loss: 0.7440\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 2s 922us/step - loss: 0.7425 - val_loss: 0.7439\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 2s 917us/step - loss: 0.7425 - val_loss: 0.7438\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 2s 912us/step - loss: 0.7425 - val_loss: 0.7439\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 2s 926us/step - loss: 0.7425 - val_loss: 0.7439\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.7425 - val_loss: 0.7438\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 2s 921us/step - loss: 0.7425 - val_loss: 0.7438\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 2s 905us/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 2s 908us/step - loss: 0.7424 - val_loss: 0.7438\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 2s 914us/step - loss: 0.7424 - val_loss: 0.7439\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 2s 917us/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 2s 964us/step - loss: 0.7424 - val_loss: 0.7435\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 2s 922us/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.7425 - val_loss: 0.7439\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 2s 908us/step - loss: 0.7426 - val_loss: 0.7437\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 2s 918us/step - loss: 0.7428 - val_loss: 0.7438\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7431 - val_loss: 0.7441\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7431 - val_loss: 0.7438\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7429 - val_loss: 0.7435\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.7428 - val_loss: 0.7437\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 2s 937us/step - loss: 0.7427 - val_loss: 0.7437\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 2s 924us/step - loss: 0.7426 - val_loss: 0.7436\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 2s 957us/step - loss: 0.7427 - val_loss: 0.7438\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 2s 978us/step - loss: 0.7427 - val_loss: 0.7439\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.7429 - val_loss: 0.7438\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.7434 - val_loss: 0.7437\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 2s 931us/step - loss: 0.7433 - val_loss: 0.7437\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.7427 - val_loss: 0.7437\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 2s 948us/step - loss: 0.7427 - val_loss: 0.7437\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "num_dim = len(X_train.columns)\n",
    "\n",
    "# Red encoder, recibe un input de dimensión num_dim\n",
    "# Entrega un output de dimensión 5\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(5),\n",
    "])\n",
    "\n",
    "# Red decoder, recibe un input de dimensión 5\n",
    "# Entrega un output de dimensión num_dim\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(num_dim),\n",
    "])\n",
    "\n",
    "# Concatenamos el encoder con el decoder\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "# Compilamos el modelo\n",
    "autoencoder.compile(\n",
    "    loss='mse', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1)\n",
    ")\n",
    "\n",
    "# El entrenamiento toma los datos originales, los codifica/decodifica \n",
    "# en vectores de la misma dimensión.\n",
    "# Decidimos que debe parar si la métrica del MSE no mejora en 10 épocas. \n",
    "autoencoder.fit(\n",
    "    X_train_std, X_train_std, \n",
    "    epochs=100, validation_data=(X_test_std, X_test_std),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "\n",
    "# Ahora vamos a reducir la dimensión del dataset de prueba\n",
    "# Simplemente llamamos al encoder\n",
    "X_auto = encoder.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467df10",
   "metadata": {},
   "source": [
    "Ahora veamos cómo resultó la reducción de dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cdb4831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.7988992e+00,  1.7810218e+00, -1.4026288e+00, -3.4711971e+00,\n",
       "         3.4450185e+00],\n",
       "       [ 1.7704525e+00, -4.4218102e+00,  3.0685527e+00,  9.8014402e+00,\n",
       "        -8.5204859e+00],\n",
       "       [-4.7570415e+00,  2.6641319e+00,  4.5884690e+00, -6.9501901e-01,\n",
       "        -4.1335206e+00],\n",
       "       ...,\n",
       "       [-2.1572463e-01,  4.8436666e+00, -3.1371403e+00, -2.0285618e+00,\n",
       "         1.5560164e+00],\n",
       "       [-1.8014403e-03,  2.0610003e+00,  3.3297570e+00, -5.3294001e+00,\n",
       "        -1.7652885e+00],\n",
       "       [ 9.4273319e+00, -5.5489469e+00, -5.5007229e+00, -8.8151836e-01,\n",
       "        -8.3772469e+00]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada3c42",
   "metadata": {},
   "source": [
    "## Probando el enfoque en un entorno de clasificación\n",
    "\n",
    "¿Cómo podemos saber si esta reducción de dimensionalidad sirve de algo? Una posibilidad es probarlo de forma indirecta: ejecutando algún tipo de tarea de aprendizaje sobre estos datos, y comparando los resultados.\n",
    "\n",
    "Aquí, comparamos con la tarea de clasificar los números de MNIST usando un árbol de decisión. Vamos a comparar el resultado de usar el árbol de decisión sobre el _dataset_ original, usando PCA, y usando un _autoencoder_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555372e",
   "metadata": {},
   "source": [
    "Partimos analizando el _dataset_ original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c8049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X_test_std, y_test, cv=5, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f89894",
   "metadata": {},
   "source": [
    "Ahora para el dataset transformado con un _autoencoder_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130b87ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_auto, y_test, cv=5, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478f28a",
   "metadata": {},
   "source": [
    "Y finalmente probamos con la reducción de dimensionalidad de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63c6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train_std)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e894a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_test_pca, y_test, cv=5, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221e39a",
   "metadata": {},
   "source": [
    "## Creando mejores autoencoders\n",
    "\n",
    "¿Es posible mejorar el desempeño del _autoencoder_? Una primera idea es agregar más capas a las redes _encoder_ y _decoder_. Por lo mismo, lo que vamos hacer es pasar de la dimensión original a 200 neuronas, luego a 50 y luego a 5. Después para decodificar, vamos a ir de 5 a 50, de 50 a 200 y de 200 a la dimensión original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2a19e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7963 - val_loss: 0.7491\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7570 - val_loss: 0.7686\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7480 - val_loss: 0.7450\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7436 - val_loss: 0.7444\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7430 - val_loss: 0.7441\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7429 - val_loss: 0.7444\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7428 - val_loss: 0.7442\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7427 - val_loss: 0.7438\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7427 - val_loss: 0.7439\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7426 - val_loss: 0.7438\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7426 - val_loss: 0.7438\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7426 - val_loss: 0.7438\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7436\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7437\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7435\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7436\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7437\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7425 - val_loss: 0.7437\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7437\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7435\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7438\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7435\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7434\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7437\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7424 - val_loss: 0.7436\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7436\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7437\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7435\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7436\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7437\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7423 - val_loss: 0.7436\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7423 - val_loss: 0.7436\n"
     ]
    }
   ],
   "source": [
    "# El input es de la dimensión original del dataset\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(200),\n",
    "    keras.layers.Dense(50),\n",
    "    keras.layers.Dense(5),\n",
    "])\n",
    "\n",
    "# El output es de la dimensión original del dataset\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(50),\n",
    "    keras.layers.Dense(200),\n",
    "    keras.layers.Dense(num_dim),\n",
    "])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "# Compilamos el modelo\n",
    "autoencoder.compile(\n",
    "    loss='mse', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1)\n",
    ")\n",
    "\n",
    "# El entrenamiento toma los datos originales, los codifica/decodifica \n",
    "# en vectores de la misma dimensión.\n",
    "# Decidimos que debe parar si la métrica del MSE no mejora en 10 épocas. \n",
    "autoencoder.fit(\n",
    "    X_train_std, X_train_std, \n",
    "    epochs=100, validation_data=(X_test_std, X_test_std),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "\n",
    "# Ahora vamos a reducir la dimensión del dataset de prueba\n",
    "# Simplemente llamamos al encoder\n",
    "X_auto_deep = encoder.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f6519",
   "metadata": {},
   "source": [
    "Veamos ahora la _performance_ en el problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09a4b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_auto_deep, y_test, cv=5, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a03fd3",
   "metadata": {},
   "source": [
    "Como vemos, no nos estamos acercando al valor del _accuracy_ sin reducción de dimensionalidad. Ahora para entender mejor el resultado, vamos a comprimir y descomprimir una imagen, visualizando su descompresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f37b902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X_test.iloc[0]\n",
    "some_digit_image = some_digit.values.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb5c36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56924  ,  3.665839 ,  2.5347252,  1.7768265, -0.9328206]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_std = std_sclr.transform([some_digit])\n",
    "some_digit_compressed = encoder.predict(some_digit_std)\n",
    "some_digit_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0cf1615",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9195a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_inv = decoder.predict(some_digit_compressed)\n",
    "some_digit_inv_no_std = std_sclr.inverse_transform(some_digit_inv)\n",
    "some_digit_inv_no_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72af6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit_image_v2 = some_digit_inv_no_std[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image_v2, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d46315",
   "metadata": {},
   "source": [
    "Como vemos, el resultado es bastante malo. De todas formas, tenemos que considerar que estamos pasando de 784 a 5 dimensiones. De todas formas, veremos que podemos mejorar esto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52784fb7",
   "metadata": {},
   "source": [
    "## Visualización de PCA\n",
    "\n",
    "Para tener un punto de referencia, vamos a hacer una compresión con PCA a 5 dimensiones de la misma imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961c2333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.03126719,  3.64113018, -7.32273826, -0.55061364,  2.77316063]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_std = std_sclr.transform([some_digit])\n",
    "some_digit_compressed = pca.transform(some_digit_std)\n",
    "some_digit_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eadeef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac53dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_inv = pca.inverse_transform(some_digit_compressed)\n",
    "some_digit_inv_no_std = std_sclr.inverse_transform(some_digit_inv)\n",
    "some_digit_inv_no_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad39f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit_image_v2_pca = some_digit_inv_no_std[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image_v2_pca, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f635f",
   "metadata": {},
   "source": [
    "Como vemos, las imágenes son bastante similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2a35a",
   "metadata": {},
   "source": [
    "## Autoencoders con activación no lineal\n",
    "\n",
    "Un segundo enfoque, y lo más clásico en la práctica, es agregar una activación no lineal al final de cada capa. En este caso usamos la función Scaled Exponential Linear Unit (SELU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf77b856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.8080 - val_loss: 0.7637\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7576 - val_loss: 0.7534\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7432 - val_loss: 0.7336\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7169 - val_loss: 0.7074\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6930 - val_loss: 0.6883\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6755 - val_loss: 0.6725\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6606 - val_loss: 0.6581\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6463 - val_loss: 0.6444\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6329 - val_loss: 0.6317\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6208 - val_loss: 0.6193\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6096 - val_loss: 0.6097\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5994 - val_loss: 0.6008\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5898 - val_loss: 0.5912\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5814 - val_loss: 0.5830\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5747 - val_loss: 0.5828\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5682 - val_loss: 0.5681\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5609 - val_loss: 0.5661\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5706 - val_loss: 0.5857\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5630 - val_loss: 0.5651\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5522 - val_loss: 0.5797\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5800 - val_loss: 0.6473\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5726 - val_loss: 0.6324\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5608 - val_loss: 0.5921\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5745 - val_loss: 0.5620\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5532 - val_loss: 0.5602\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5724 - val_loss: 0.5877\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5803 - val_loss: 0.5843\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5955 - val_loss: 0.6046\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5592 - val_loss: 0.5486\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5588 - val_loss: 0.6016\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5474 - val_loss: 0.5480\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5265 - val_loss: 0.5594\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5432 - val_loss: 0.5505\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5403 - val_loss: 0.5457\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5334 - val_loss: 0.5284\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5151 - val_loss: 0.5390\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5167 - val_loss: 0.5406\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8014 - val_loss: 0.7082\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6728 - val_loss: 0.6720\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6317 - val_loss: 0.6193\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6039 - val_loss: 0.6167\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6141 - val_loss: 0.5979\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6126 - val_loss: 0.5950\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6143 - val_loss: 0.5975\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5810 - val_loss: 0.5788\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(200, activation='selu'),\n",
    "    keras.layers.Dense(50, activation='selu'),\n",
    "    keras.layers.Dense(5, activation='selu'),\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(50,activation='selu'),\n",
    "    keras.layers.Dense(200, activation='selu'),\n",
    "    keras.layers.Dense(num_dim, activation='selu'),\n",
    "])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "# Compilamos el modelo\n",
    "autoencoder.compile(\n",
    "    loss='mse', \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1)\n",
    ")\n",
    "\n",
    "# El entrenamiento toma los datos originales, los codifica/decodifica \n",
    "# en vectores de la misma dimensión.\n",
    "# Decidimos que debe parar si la métrica del MSE no mejora en 10 épocas. \n",
    "autoencoder.fit(\n",
    "    X_train_std, X_train_std, \n",
    "    epochs=100, validation_data=(X_test_std, X_test_std),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "\n",
    "# Ahora vamos a reducir la dimensión del dataset de prueba\n",
    "# Simplemente llamamos al encoder\n",
    "X_auto_deep_relu = encoder.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e505219",
   "metadata": {},
   "source": [
    "Ahora, vamos a probar el desempeño en el problema de clasificación para este _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d3b7b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6845"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_auto_deep_relu, y_test, cv=5, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836b916",
   "metadata": {},
   "source": [
    "Como vemos, hemos mejorado bastante con respecto a nuestro _baseline_. Finalmente, vamos a repetir el ejercicio de visualización, pero ahora con esto _autoencoder_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f254059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7580785 , -1.2411677 ,  2.5868561 , -0.44534963, -0.796676  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_std = std_sclr.transform([some_digit])\n",
    "some_digit_compressed = encoder.predict(some_digit_std)\n",
    "some_digit_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad7974ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07541635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_inv = decoder.predict(some_digit_compressed)\n",
    "some_digit_inv_no_std = std_sclr.inverse_transform(some_digit_inv)\n",
    "some_digit_inv_no_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56785d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit_image_v2 = some_digit_inv_no_std[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image_v2, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7fda4",
   "metadata": {},
   "source": [
    "Como vemos, es una mejora notable respecto a las otras compresiones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
